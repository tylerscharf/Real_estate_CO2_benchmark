{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f8460b3-f414-40fc-87c1-c2b05fdf9271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Skipping Classification_Results/Kilroy_Reality_2011_nan_2011_classification.csv, error loading: No columns to parse from file\n",
      "[INFO] Loaded 1447 statements from 11 companies\n",
      "[WARNING] Error generating taxonomy visualizations: name 'catA_flat' is not defined\n",
      "\n",
      "=== Taxonomy A Distribution (Forward-Looking) ===\n",
      "Category counts:\n",
      "2      449\n",
      "3      273\n",
      "5      235\n",
      "4      107\n",
      "6       60\n",
      "2.0     56\n",
      "3.0     15\n",
      "5.0     10\n",
      "1.0      3\n",
      "4.0      1\n",
      "6.0      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total statements with forward-looking commitments: 1210\n",
      "\n",
      "=== Taxonomy B Distribution (Past Commitments) ===\n",
      "Category counts:\n",
      "3.0    342\n",
      "3      148\n",
      "2.0     30\n",
      "5.0     23\n",
      "2       15\n",
      "5       14\n",
      "4.0      4\n",
      "1.0      3\n",
      "4        2\n",
      "6.0      2\n",
      "1        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total statements with past achievements: 584\n",
      "\n",
      "=== Company-Level Analysis ===\n",
      "\n",
      "Commitments by company:\n",
      "                                          Total Statements  Forward-Looking  \\\n",
      "Category                                                                      \n",
      "AG_Real_Estate                                          62               50   \n",
      "Brookfield_Asset_Management                            166              133   \n",
      "China_Overseas_Property_Holdings_Limited                83               70   \n",
      "China_Vanke                                            165              122   \n",
      "Country_Garden_Holdings                                 92               77   \n",
      "Hines                                                   43               35   \n",
      "Kilroy_Reality                                         482              360   \n",
      "New_World_Development_Company_Limited                  163              137   \n",
      "Prologis__Inc.                                          54               45   \n",
      "Savills_UK                                              45               39   \n",
      "Seazen_Group                                            92               73   \n",
      "\n",
      "                                          Past Achievements  \n",
      "Category                                                     \n",
      "AG_Real_Estate                                           27  \n",
      "Brookfield_Asset_Management                              59  \n",
      "China_Overseas_Property_Holdings_Limited                 26  \n",
      "China_Vanke                                              63  \n",
      "Country_Garden_Holdings                                  34  \n",
      "Hines                                                    21  \n",
      "Kilroy_Reality                                          225  \n",
      "New_World_Development_Company_Limited                    53  \n",
      "Prologis__Inc.                                           19  \n",
      "Savills_UK                                               16  \n",
      "Seazen_Group                                             34  \n",
      "\n",
      "=== Top terms per cluster (k=6) ===\n",
      "\n",
      "Cluster #0 (60 statements):\n",
      "Top terms: net, net zero, zero, 2050, emissions, carbon, zero 2050, ambition, zero carbon, assets\n",
      "\n",
      "Example statements:\n",
      "- The Shanghai Fengxian Lingang Logistics Park, VX Logistics’s first pilot park of carbon management platform, opened on 18 April 2023. It is the first ...\n",
      "- Climate Change Actions Accelerating Towards Net Zero...\n",
      "\n",
      "Cluster #1 (795 statements):\n",
      "Top terms: sustainability, management, sustainable, 2023, environmental, business, development, quality, safety, year\n",
      "\n",
      "Example statements:\n",
      "- This report contains forward-looking statements, including but not limited to words or phrases, such as “will”, “expects”, “forecasts”, “future”, “aim...\n",
      "- In 2023, we continued to forge ahead in compliant operation and integrate sustainable development into every detail of our operations....\n",
      "\n",
      "Cluster #2 (89 statements):\n",
      "Top terms: climate, change, climate change, risks, opportunities, climate related, related, risks opportunities, risk, related risks\n",
      "\n",
      "Example statements:\n",
      "- Integrate comprehensive sustainability-related risks, such as climate risk, into enterprise risk management....\n",
      "- Identifying opportunities brought about by climate change Setting management metrics and targets for climate change response...\n",
      "\n",
      "Cluster #3 (216 statements):\n",
      "Top terms: green, leed, projects, development, buildings, building, certification, carbon, certifications, gold\n",
      "\n",
      "Example statements:\n",
      "- Vanke has long been committed to promoting green and low-carbon development and leading the industry....\n",
      "- Vanke has never ceased to explore green and low-carbon development....\n",
      "\n",
      "Cluster #4 (179 statements):\n",
      "Top terms: energy, consumption, water, reduction, energy consumption, portfolio, efficiency, million, renewable, usage\n",
      "\n",
      "Example statements:\n",
      "- Through a range of technical measures, including building energy conservation, renewable energy utilisation, water conservation, and solid waste recyc...\n",
      "- Continuously promoting the energy-saving and consumption-reducing transformation of facilities and equipment...\n",
      "\n",
      "Cluster #5 (108 statements):\n",
      "Top terms: emissions, scope, ghg, scope emissions, ghg emissions, carbon, 2020, gas, year, reduction\n",
      "\n",
      "Example statements:\n",
      "- The Company set key ESG targets covering greenhouse gas emissions, waste management, and resource use....\n",
      "- By 2030, the carbon emissions of at least 20 shopping centres to be reduced by 9% against a 2021 baseline....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Successfully generated clustering visualizations\n",
      "\n",
      "Number of reports per company:\n",
      "Category\n",
      "AG_Real_Estate                              2\n",
      "Brookfield_Asset_Management                 1\n",
      "China_Overseas_Property_Holdings_Limited    1\n",
      "China_Vanke                                 1\n",
      "Country_Garden_Holdings                     1\n",
      "Hines                                       1\n",
      "Kilroy_Reality                              9\n",
      "New_World_Development_Company_Limited       2\n",
      "Prologis__Inc.                              1\n",
      "Savills_UK                                  2\n",
      "Seazen_Group                                1\n",
      "Name: Year, dtype: int64\n",
      "\n",
      "[INFO] Analysis results saved to 3_report_commitments/sustainability_commitments_analysis.csv\n",
      "[INFO] Cluster descriptions saved to 3_report_commitments/cluster_descriptions.json\n",
      "\n",
      "[INFO] Visualizations have been saved to 3_report_commitments/figures/\n",
      "[INFO] Summary statistics saved to 3_report_commitments/analysis_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "\n",
    "def load_all_csv_reports(base_dir):\n",
    "    \"\"\"\n",
    "    Load all CSV files under `base_dir` and concatenate\n",
    "    them into a single pandas DataFrame.\n",
    "    \n",
    "    The CSVs contain:\n",
    "        - Category (Company name)\n",
    "        - Year\n",
    "        - Statement\n",
    "        - TaxonomyA_Categories\n",
    "        - TaxonomyA_Explanations\n",
    "        - TaxonomyB_Categories\n",
    "        - TaxonomyB_Explanations\n",
    "    \"\"\"\n",
    "    csv_files = glob.glob(os.path.join(base_dir, \"*.csv\"))\n",
    "    all_dfs = []\n",
    "    for fpath in csv_files:\n",
    "        try:\n",
    "            df_temp = pd.read_csv(fpath)\n",
    "            # Add source file info\n",
    "            df_temp[\"SourceCSV\"] = os.path.basename(fpath)\n",
    "            all_dfs.append(df_temp)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Skipping {fpath}, error loading: {e}\")\n",
    "    \n",
    "    if all_dfs:\n",
    "        df = pd.concat(all_dfs, ignore_index=True)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"[INFO] No CSV files found in directory.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def analyze_taxonomy_distribution(df):\n",
    "    \"\"\"\n",
    "    Shows how often each taxonomy category appears in the dataset.\n",
    "    Analyzes both TaxonomyA (Forward-Looking) and TaxonomyB (Past Commitments).\n",
    "    \"\"\"\n",
    "    # For Taxonomy A (Forward-Looking)\n",
    "    catA_series = df[\"TaxonomyA_Categories\"].dropna().astype(str).apply(lambda x: [s.strip() for s in str(x).split(\",\")])\n",
    "    catA_flat = []\n",
    "    for row in catA_series:\n",
    "        catA_flat.extend([c for c in row if c and c != 'nan'])\n",
    "\n",
    "    catA_counts = pd.Series(catA_flat).value_counts()\n",
    "    \n",
    "    # For Taxonomy B (Past Commitments)\n",
    "    catB_series = df[\"TaxonomyB_Categories\"].dropna().astype(str).apply(lambda x: [s.strip() for s in str(x).split(\",\")])\n",
    "    catB_flat = []\n",
    "    for row in catB_series:\n",
    "        catB_flat.extend([c for c in row if c and c != 'nan'])\n",
    "\n",
    "    catB_counts = pd.Series(catB_flat).value_counts()\n",
    "    \n",
    "    print(\"\\n=== Taxonomy A Distribution (Forward-Looking) ===\")\n",
    "    print(\"Category counts:\")\n",
    "    print(catA_counts)\n",
    "    print(f\"\\nTotal statements with forward-looking commitments: {len(catA_flat)}\")\n",
    "    \n",
    "    print(\"\\n=== Taxonomy B Distribution (Past Commitments) ===\")\n",
    "    print(\"Category counts:\")\n",
    "    print(catB_counts)\n",
    "    print(f\"\\nTotal statements with past achievements: {len(catB_flat)}\")\n",
    "    \n",
    "    # Company-level analysis\n",
    "    print(\"\\n=== Company-Level Analysis ===\")\n",
    "    company_stats = df.groupby(\"Category\").agg({\n",
    "        \"Statement\": \"count\",\n",
    "        \"TaxonomyA_Categories\": lambda x: x.notna().sum(),\n",
    "        \"TaxonomyB_Categories\": lambda x: x.notna().sum()\n",
    "    }).rename(columns={\n",
    "        \"Statement\": \"Total Statements\",\n",
    "        \"TaxonomyA_Categories\": \"Forward-Looking\",\n",
    "        \"TaxonomyB_Categories\": \"Past Achievements\"\n",
    "    })\n",
    "    print(\"\\nCommitments by company:\")\n",
    "    print(company_stats)\n",
    "\n",
    "def cluster_statements(df, n_clusters=6):\n",
    "    \"\"\"\n",
    "    Performs KMeans clustering of statement text\n",
    "    to group statements with similar themes.\n",
    "    Returns the clustered dataframe and cluster descriptions.\n",
    "    \"\"\"\n",
    "    # Some CSV rows might have missing statements\n",
    "    df_nonempty = df.dropna(subset=[\"Statement\"])\n",
    "    statements = df_nonempty[\"Statement\"].astype(str).tolist()\n",
    "\n",
    "    # TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english', \n",
    "        max_features=2000,\n",
    "        ngram_range=(1, 2)  # Include bigrams for better context\n",
    "    )\n",
    "    X = vectorizer.fit_transform(statements)\n",
    "    \n",
    "    # KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # Add cluster labels back to the dataframe\n",
    "    df_nonempty[\"Cluster\"] = kmeans.labels_\n",
    "\n",
    "    # Analyze top features per cluster and create descriptions\n",
    "    order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    cluster_descriptions = []\n",
    "    print(f\"\\n=== Top terms per cluster (k={n_clusters}) ===\")\n",
    "    for i in range(n_clusters):\n",
    "        top_indices = order_centroids[i, :10]\n",
    "        top_terms = [terms[idx] for idx in top_indices]\n",
    "        cluster_size = int(sum(kmeans.labels_ == i))  # Convert np.int64 to Python int\n",
    "        \n",
    "        # Get example statements\n",
    "        cluster_examples = df_nonempty[df_nonempty[\"Cluster\"] == i][\"Statement\"].head(2)\n",
    "        example_texts = [stmt[:150] + \"...\" for stmt in cluster_examples]\n",
    "        \n",
    "        # Create cluster description\n",
    "        description = {\n",
    "            \"cluster\": int(i),  # Convert np.int64 to Python int\n",
    "            \"size\": cluster_size,\n",
    "            \"top_terms\": list(top_terms),  # Convert np.ndarray to Python list\n",
    "            \"examples\": list(example_texts)  # Convert pd.Series to Python list\n",
    "        }\n",
    "        cluster_descriptions.append(description)\n",
    "        \n",
    "        print(f\"\\nCluster #{i} ({cluster_size} statements):\")\n",
    "        print(f\"Top terms: {', '.join(top_terms)}\")\n",
    "        print(\"\\nExample statements:\")\n",
    "        for stmt in example_texts:\n",
    "            print(f\"- {stmt}\")\n",
    "\n",
    "    return df_nonempty, cluster_descriptions\n",
    "\n",
    "def visualize_normalized_commitments(df, output_dir):\n",
    "    \"\"\"\n",
    "    Creates a normalized visualization of commitments per report for each company\n",
    "    with detailed taxonomy descriptions\n",
    "    \"\"\"\n",
    "    # Count number of unique reports per company\n",
    "    reports_per_company = df.groupby(\"Category\")[\"Year\"].nunique()\n",
    "    \n",
    "    # Get the existing commitment counts\n",
    "    company_stats = df.groupby(\"Category\").agg({\n",
    "        \"TaxonomyA_Categories\": lambda x: x.notna().sum(),\n",
    "        \"TaxonomyB_Categories\": lambda x: x.notna().sum()\n",
    "    })\n",
    "    \n",
    "    # Normalize by number of reports\n",
    "    normalized_stats = company_stats.div(reports_per_company, axis=0)\n",
    "    \n",
    "    # Create figure with extra space for descriptions\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Create gridspec for bar plot and text\n",
    "    gs = fig.add_gridspec(2, 1, height_ratios=[2, 1])\n",
    "    \n",
    "    # Plot normalized commitments in top subplot\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    normalized_stats.plot(kind='bar', stacked=True, ax=ax, \n",
    "                         color=['skyblue', 'lightgreen'])\n",
    "    plt.title('Average Commitments per Report by Company', pad=20)\n",
    "    plt.xlabel('Company')\n",
    "    plt.ylabel('Average Number of Commitments per Report')\n",
    "    plt.legend(['Forward-Looking (Taxonomy A)', 'Past Achievements (Taxonomy B)'],\n",
    "              title='Commitment Type')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add taxonomy descriptions in bottom subplot\n",
    "    taxonomy_text = \"\"\"\n",
    "Taxonomy A: Present/Future Commitments\n",
    "1. No Mention - General sustainability statements without specific emissions targets\n",
    "2. Generic/High-Level - Non-specific intent to reduce emissions\n",
    "3. Specific Numeric Target - Quantitative goals with timeline\n",
    "4. Net-Zero/Carbon-Neutral - Explicit net-zero commitments\n",
    "5. Detailed Plan/Roadmap - Specific implementation steps\n",
    "6. Science-Based/Framework - SBTi, TCFD alignment\n",
    "\n",
    "Taxonomy B: References to Past Commitments\n",
    "1. No Past Commitment - No prior targets mentioned\n",
    "2. Status Unknown - Referenced but unclear\n",
    "3. Progress/Achieved - Met or partially met targets\n",
    "4. Shortfall - Missed targets\n",
    "5. Updated/Extended - Revised goals\n",
    "6. Discontinued - Replaced targets\n",
    "\"\"\"\n",
    "    \n",
    "    # Add text box with taxonomy descriptions\n",
    "    plt.figtext(0.1, 0.02, taxonomy_text, fontsize=9, \n",
    "                bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(bottom=0.4)  # Make room for text\n",
    "    \n",
    "    # Save the plot\n",
    "    fig_dir = os.path.join(output_dir, \"figures\")\n",
    "    os.makedirs(fig_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(fig_dir, 'company_commitments.png'), \n",
    "                dpi=300, bbox_inches='tight', pad_inches=0.5)\n",
    "    plt.close()\n",
    "\n",
    "def visualize_taxonomy_distribution(df, output_dir):\n",
    "    \"\"\"\n",
    "    Creates visualizations for taxonomy distributions:\n",
    "    1. Bar plots of taxonomy categories with descriptions\n",
    "    2. Company-wise normalized commitments\n",
    "    \"\"\"\n",
    "    # Set style to a default matplotlib style\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    # Create figures directory\n",
    "    fig_dir = os.path.join(output_dir, \"figures\")\n",
    "    os.makedirs(fig_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Define taxonomy descriptions\n",
    "        taxonomy_A_desc = {\n",
    "            \"1\": \"No Mention\\n(General sustainability statements)\",\n",
    "            \"2\": \"Generic/High-Level Commitment\\n(Non-specific intent to reduce emissions)\",\n",
    "            \"3\": \"Specific Numeric Target\\n(Quantitative goals with timeline)\",\n",
    "            \"4\": \"Net-Zero/Carbon-Neutral Target\\n(Explicit net-zero commitments)\",\n",
    "            \"5\": \"Detailed Plan/Roadmap\\n(Specific implementation steps)\",\n",
    "            \"6\": \"Science-Based/Framework\\n(SBTi, TCFD alignment)\"\n",
    "        }\n",
    "        \n",
    "        taxonomy_B_desc = {\n",
    "            \"1\": \"No Past Commitment\\n(No prior targets mentioned)\",\n",
    "            \"2\": \"Past Commitment Status Unknown\\n(Referenced but unclear)\",\n",
    "            \"3\": \"Acknowledged Progress/Achieved\\n(Met or partially met)\",\n",
    "            \"4\": \"Acknowledged Shortfall\\n(Missed targets)\",\n",
    "            \"5\": \"Updated/Extended Commitments\\n(Revised goals)\",\n",
    "            \"6\": \"Discontinued/Superseded\\n(Replaced targets)\"\n",
    "        }\n",
    "        \n",
    "        # Create figure with two subplots and extra space for text\n",
    "        fig = plt.figure(figsize=(15, 16))\n",
    "        gs = fig.add_gridspec(3, 1, height_ratios=[1, 1, 0.2])\n",
    "        \n",
    "        # Process and plot Taxonomy A\n",
    "        ax1 = fig.add_subplot(gs[0])\n",
    "        catA_series = df[\"TaxonomyA_Categories\"].dropna().astype(str).apply(\n",
    "            lambda x: [s.strip() for s in str(x).split(\",\")]\n",
    "        )\n",
    "        catA_counts = pd.Series([c for row in catA_series for c in row if c and c != 'nan']).value_counts()\n",
    "        \n",
    "        # Rename index with descriptions\n",
    "        catA_counts.index = [taxonomy_A_desc.get(str(idx), str(idx)) for idx in catA_counts.index]\n",
    "        \n",
    "        # Plot Taxonomy A\n",
    "        bars1 = catA_counts.plot(kind='bar', ax=ax1, color='skyblue')\n",
    "        ax1.set_title('Taxonomy A: Present/Future Commitments\\nDistribution of Forward-Looking Statements', pad=20)\n",
    "        ax1.set_xlabel('')\n",
    "        ax1.set_ylabel('Count')\n",
    "        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on the bars\n",
    "        for i, v in enumerate(catA_counts):\n",
    "            ax1.text(i, v, str(v), ha='center', va='bottom')\n",
    "        \n",
    "        # Process and plot Taxonomy B\n",
    "        ax2 = fig.add_subplot(gs[1])\n",
    "        catB_series = df[\"TaxonomyB_Categories\"].dropna().astype(str).apply(\n",
    "            lambda x: [s.strip() for s in str(x).split(\",\")]\n",
    "        )\n",
    "        catB_counts = pd.Series([c for row in catB_series for c in row if c and c != 'nan']).value_counts()\n",
    "        \n",
    "        # Rename index with descriptions\n",
    "        catB_counts.index = [taxonomy_B_desc.get(str(idx), str(idx)) for idx in catB_counts.index]\n",
    "        \n",
    "        # Plot Taxonomy B\n",
    "        bars2 = catB_counts.plot(kind='bar', ax=ax2, color='lightgreen')\n",
    "        ax2.set_title('Taxonomy B: References to Past Commitments\\nDistribution of Historical Achievement Statements', pad=20)\n",
    "        ax2.set_xlabel('')\n",
    "        ax2.set_ylabel('Count')\n",
    "        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on the bars\n",
    "        for i, v in enumerate(catB_counts):\n",
    "            ax2.text(i, v, str(v), ha='center', va='bottom')\n",
    "        \n",
    "        # Add summary text at the bottom\n",
    "        summary_text = (\n",
    "            f\"Total Forward-Looking Commitments: {len(catA_flat)}\\n\"\n",
    "            f\"Total Past Achievement References: {len(catB_flat)}\\n\"\n",
    "            f\"Number of Companies: {df['Category'].nunique()}\"\n",
    "        )\n",
    "        fig.text(0.1, 0.02, summary_text, fontsize=10, \n",
    "                bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(fig_dir, 'taxonomy_distributions.png'), \n",
    "                   dpi=300, bbox_inches='tight', pad_inches=0.5)\n",
    "        plt.close()\n",
    "        \n",
    "        # Create normalized commitments visualization\n",
    "        reports_per_company = df.groupby(\"Category\")[\"Year\"].nunique()\n",
    "        company_stats = df.groupby(\"Category\").agg({\n",
    "            \"TaxonomyA_Categories\": lambda x: x.notna().sum(),\n",
    "            \"TaxonomyB_Categories\": lambda x: x.notna().sum()\n",
    "        })\n",
    "        \n",
    "        # Normalize by number of reports\n",
    "        normalized_stats = company_stats.div(reports_per_company, axis=0)\n",
    "        \n",
    "        # Plot normalized commitments\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        normalized_stats.plot(kind='bar', stacked=True, ax=ax, \n",
    "                         color=['skyblue', 'lightgreen'])\n",
    "        plt.title('Average Commitments per Report by Company', pad=20)\n",
    "        plt.xlabel('Company')\n",
    "        plt.ylabel('Average Number of Commitments per Report')\n",
    "        plt.legend(['Forward-Looking (Taxonomy A)', 'Past Achievements (Taxonomy B)'],\n",
    "                  title='Commitment Type')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(fig_dir, 'company_commitments.png'), \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"[INFO] Successfully generated taxonomy distribution visualizations\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Error generating taxonomy visualizations: {str(e)}\")\n",
    "\n",
    "def visualize_clusters(df_clustered, cluster_descriptions, output_dir):\n",
    "    \"\"\"\n",
    "    Creates visualizations for clustering results:\n",
    "    1. Cluster size distribution with descriptions\n",
    "    2. Heatmap of company distribution across clusters (in percentages)\n",
    "    \"\"\"\n",
    "    fig_dir = os.path.join(output_dir, \"figures\")\n",
    "    os.makedirs(fig_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # 1. Cluster Size Distribution with Descriptions\n",
    "        plt.figure(figsize=(15, 12))  # Increased height for more description space\n",
    "        \n",
    "        # Create the bar plot\n",
    "        cluster_sizes = df_clustered['Cluster'].value_counts().sort_index()\n",
    "        ax = cluster_sizes.plot(kind='bar', color='skyblue')\n",
    "        \n",
    "        plt.title('Distribution of Statements Across Clusters', pad=20)\n",
    "        plt.xlabel('Cluster')\n",
    "        plt.ylabel('Number of Statements')\n",
    "        plt.xticks(rotation=0)\n",
    "        \n",
    "        # Define cluster interpretations based on terms and examples\n",
    "        cluster_interpretations = {\n",
    "            0: {\n",
    "                \"title\": \"General Sustainability Statements\",\n",
    "                \"description\": \"Statements that discuss general sustainability practices and environmental responsibility without specific emissions targets.\",\n",
    "                \"typical_content\": \"References to sustainability reports, environmental management, and general green initiatives.\"\n",
    "            },\n",
    "            1: {\n",
    "                \"title\": \"Specific Emissions Targets\",\n",
    "                \"description\": \"Quantitative commitments to reduce carbon emissions with specific percentage targets and deadlines.\",\n",
    "                \"typical_content\": \"Numeric reduction targets, timeline commitments, and scope-specific goals (Scope 1, 2, or 3).\"\n",
    "            },\n",
    "            2: {\n",
    "                \"title\": \"Net-Zero Commitments\",\n",
    "                \"description\": \"Explicit commitments to achieve net-zero or carbon neutrality by a specific date.\",\n",
    "                \"typical_content\": \"Net-zero targets, carbon neutrality goals, and long-term climate commitments.\"\n",
    "            },\n",
    "            3: {\n",
    "                \"title\": \"Implementation Strategies\",\n",
    "                \"description\": \"Detailed plans and specific measures for achieving emissions reduction targets.\",\n",
    "                \"typical_content\": \"Energy efficiency initiatives, renewable energy adoption, and specific technological solutions.\"\n",
    "            },\n",
    "            4: {\n",
    "                \"title\": \"Progress Reporting\",\n",
    "                \"description\": \"Statements reporting on progress towards previously set targets and achievements.\",\n",
    "                \"typical_content\": \"Achievement updates, progress metrics, and performance against targets.\"\n",
    "            },\n",
    "            5: {\n",
    "                \"title\": \"Framework Alignment\",\n",
    "                \"description\": \"References to external frameworks and standards for emissions reduction.\",\n",
    "                \"typical_content\": \"SBTi alignment, TCFD reporting, and industry standard compliance.\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Add cluster descriptions as text below the plot\n",
    "        description_text = []\n",
    "        for cluster_id, interp in cluster_interpretations.items():\n",
    "            desc = cluster_descriptions[cluster_id]\n",
    "            cluster_text = (\n",
    "                f\"Cluster {cluster_id}: {interp['title']} ({desc['size']} statements)\\n\"\n",
    "                f\"Description: {interp['description']}\\n\"\n",
    "                f\"Typical Content: {interp['typical_content']}\\n\"\n",
    "                f\"Example: {desc['examples'][0]}\\n\"\n",
    "            )\n",
    "            description_text.append(cluster_text)\n",
    "        \n",
    "        # Add descriptions as text\n",
    "        plt.figtext(0.1, -0.6, '\\n\\n'.join(description_text), \n",
    "                   fontsize=9, wrap=True, \n",
    "                   bbox=dict(facecolor='white', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        # Adjust bottom margin to fit descriptions\n",
    "        plt.subplots_adjust(bottom=0.5)\n",
    "        plt.savefig(os.path.join(fig_dir, 'cluster_distribution.png'), \n",
    "                    dpi=300, bbox_inches='tight', pad_inches=1.5)  # Increased padding\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Company distribution across clusters (as percentages)\n",
    "        company_cluster_dist = pd.crosstab(df_clustered['Category'], df_clustered['Cluster'])\n",
    "        \n",
    "        # Convert to percentages (rows sum to 100%)\n",
    "        company_cluster_pct = company_cluster_dist.div(company_cluster_dist.sum(axis=1), axis=0) * 100\n",
    "        \n",
    "        # Reset all matplotlib parameters to default\n",
    "        plt.rcdefaults()\n",
    "        plt.style.use('default')\n",
    "        \n",
    "        # Create a new figure with specified size\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Create heatmap with adjusted parameters\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        # Create heatmap\n",
    "        heatmap = sns.heatmap(company_cluster_pct, \n",
    "                            cmap='YlOrRd',\n",
    "                            annot=True,\n",
    "                            fmt='.1f',\n",
    "                            annot_kws={'size': 9},\n",
    "                            cbar_kws={'label': 'Percentage of Company Statements'},\n",
    "                            square=True,\n",
    "                            vmin=0,\n",
    "                            vmax=100,\n",
    "                            ax=ax)\n",
    "        \n",
    "        # Ensure all annotations are visible by adjusting their properties\n",
    "        for t in ax.texts:\n",
    "            t.set_text(f\"{float(t.get_text()):.1f}\")\n",
    "            t.set_fontweight('bold')\n",
    "        \n",
    "        # Customize title and labels\n",
    "        ax.set_title('Company Distribution Across Clusters (Percentage)', pad=20, fontsize=12)\n",
    "        ax.set_xlabel('Cluster', fontsize=10)\n",
    "        ax.set_ylabel('Company', fontsize=10)\n",
    "        \n",
    "        # Rotate x-axis labels for better readability\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.yticks(rotation=0)\n",
    "        \n",
    "        # Adjust layout to prevent label cutoff\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save with extra padding and high DPI\n",
    "        plt.savefig(os.path.join(fig_dir, 'company_cluster_distribution.png'), \n",
    "                   dpi=300, \n",
    "                   bbox_inches='tight',\n",
    "                   pad_inches=0.5)\n",
    "        \n",
    "        # Clear the current figure\n",
    "        plt.close('all')\n",
    "        \n",
    "        print(\"[INFO] Successfully generated clustering visualizations\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Error generating cluster visualizations: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # Path to classification results\n",
    "    base_dir = \"Classification_Results\"\n",
    "    \n",
    "    # 1. Load all CSVs into a single DataFrame\n",
    "    df_all = load_all_csv_reports(base_dir)\n",
    "    print(f\"[INFO] Loaded {len(df_all)} statements from {df_all['Category'].nunique()} companies\")\n",
    "\n",
    "    if df_all.empty:\n",
    "        return  # nothing to analyze\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = \"3_report_commitments\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Generate visualizations for taxonomy distributions\n",
    "    visualize_taxonomy_distribution(df_all, output_dir)\n",
    "    \n",
    "    # Generate normalized commitments with taxonomy descriptions\n",
    "    visualize_normalized_commitments(df_all, output_dir)\n",
    "    \n",
    "    # 2. Analyze taxonomy distributions and company-level stats\n",
    "    analyze_taxonomy_distribution(df_all)\n",
    "    \n",
    "    # 3. Perform clustering and visualize results\n",
    "    df_clustered, cluster_descriptions = cluster_statements(df_all, n_clusters=6)\n",
    "    visualize_clusters(df_clustered, cluster_descriptions, output_dir)\n",
    "    \n",
    "    # Print number of reports per company\n",
    "    reports_per_company = df_all.groupby(\"Category\")[\"Year\"].nunique()\n",
    "    print(\"\\nNumber of reports per company:\")\n",
    "    print(reports_per_company)\n",
    "    \n",
    "    # 4. Save results\n",
    "    output_csv = os.path.join(output_dir, \"sustainability_commitments_analysis.csv\")\n",
    "    df_clustered.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n[INFO] Analysis results saved to {output_csv}\")\n",
    "    \n",
    "    # Save cluster descriptions\n",
    "    cluster_desc_file = os.path.join(output_dir, \"cluster_descriptions.json\")\n",
    "    with open(cluster_desc_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(cluster_descriptions, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"[INFO] Cluster descriptions saved to {cluster_desc_file}\")\n",
    "    \n",
    "    print(\"\\n[INFO] Visualizations have been saved to 3_report_commitments/figures/\")\n",
    "    \n",
    "    # Save summary statistics\n",
    "    summary_stats = pd.DataFrame({\n",
    "        'Metric': [\n",
    "            'Total Companies',\n",
    "            'Total Statements',\n",
    "            'Forward-Looking Commitments',\n",
    "            'Past Achievements',\n",
    "            'Statements with Both'\n",
    "        ],\n",
    "        'Value': [\n",
    "            df_all['Category'].nunique(),\n",
    "            len(df_all),\n",
    "            df_all['TaxonomyA_Categories'].notna().sum(),\n",
    "            df_all['TaxonomyB_Categories'].notna().sum(),\n",
    "            (df_all['TaxonomyA_Categories'].notna() & df_all['TaxonomyB_Categories'].notna()).sum()\n",
    "        ]\n",
    "    })\n",
    "    summary_csv = os.path.join(output_dir, \"analysis_summary.csv\")\n",
    "    summary_stats.to_csv(summary_csv, index=False)\n",
    "    print(f\"[INFO] Summary statistics saved to {summary_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
